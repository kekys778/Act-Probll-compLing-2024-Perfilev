{"cells":[{"cell_type":"markdown","id":"ca9018a8-98d3-43e9-aadb-e7a7bee17a85","metadata":{"id":"ca9018a8-98d3-43e9-aadb-e7a7bee17a85"},"source":["## Fastext своими руками\n","\n","Fastext использует те же самые алгоритмы, что и word2vec. Единственное (но очень значимое) отличие в том, что в fastext используются не только слова, но и символьные нграммы. Это частично помогает решить проблему с несловарными словами. Если в словаре word2vec модели нет нужного слова, то никакого вектора для него создать не получится. В fastext же, если слова нет в словаре целиком, то можно проверить по словарю символьные нграммы этого слова и составить итоговый вектор из них. Большинство несловарных слов сильно пересекаются со словарными (основами, аффиксами) и за счет этого найденный вектор получается достаточно хороший.\n","Реализовать простую версию fastext немного сложнее, поэтому я вынес его в отдельный ноутбук."]},{"cell_type":"code","execution_count":37,"id":"9be38530-a130-4f1f-baf6-d9d4f56396e3","metadata":{"id":"9be38530-a130-4f1f-baf6-d9d4f56396e3","executionInfo":{"status":"ok","timestamp":1748882133474,"user_tz":-180,"elapsed":26,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from string import punctuation\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_distances\n","import random\n","\n","from IPython.display import Image\n","from IPython.core.display import HTML\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":20,"id":"b83e8611-49e4-4001-8046-cda52b85e965","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b83e8611-49e4-4001-8046-cda52b85e965","executionInfo":{"status":"ok","timestamp":1748881989873,"user_tz":-180,"elapsed":27,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}},"outputId":"2488f671-79e4-49d3-d01d-e666b4660f70"},"outputs":[{"output_type":"stream","name":"stdout","text":["3.8.0\n"]}],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"torch\"\n","# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n","\n","\n","import keras\n","print(keras.__version__)"]},{"cell_type":"markdown","id":"d9e201b4-924b-4b88-ab5f-facca2e9e511","metadata":{"id":"d9e201b4-924b-4b88-ab5f-facca2e9e511"},"source":["Возьмем тот же небольшой кусок википедии"]},{"cell_type":"code","execution_count":21,"id":"73b1f1d1-53c4-424b-b34b-4e5e772e1c99","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73b1f1d1-53c4-424b-b34b-4e5e772e1c99","executionInfo":{"status":"ok","timestamp":1748881991450,"user_tz":-180,"elapsed":1580,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}},"outputId":"b66a3d03-29f4-43b3-d439-4188b3909237"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-06-02 16:33:10--  https://github.com/mannefedov/compling_nlp_hse_course/raw/refs/heads/master/notebooks/word_embeddings/wiki_data.txt\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/refs/heads/master/notebooks/word_embeddings/wiki_data.txt [following]\n","--2025-06-02 16:33:10--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/refs/heads/master/notebooks/word_embeddings/wiki_data.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 68582461 (65M) [text/plain]\n","Saving to: ‘wiki_data.txt.1’\n","\n","wiki_data.txt.1     100%[===================>]  65.41M   240MB/s    in 0.3s    \n","\n","2025-06-02 16:33:10 (240 MB/s) - ‘wiki_data.txt.1’ saved [68582461/68582461]\n","\n"]}],"source":["# в нашем корпусе 20к текстов\n","!wget https://github.com/mannefedov/compling_nlp_hse_course/raw/refs/heads/master/notebooks/word_embeddings/wiki_data.txt\n","wiki = open('wiki_data.txt').read().split('\\n')"]},{"cell_type":"code","execution_count":22,"id":"f156ffec-37a8-4860-8489-53ea24f4761f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"id":"f156ffec-37a8-4860-8489-53ea24f4761f","executionInfo":{"status":"ok","timestamp":1748881991554,"user_tz":-180,"elapsed":102,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}},"outputId":"7d0a6001-e57c-4de9-bbf2-7ef220a63b28"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'######Новостройка (Нижегородская область)############Новостро́йка — сельский посёлок в Дивеевском районе Нижегородской области. Входит в состав Сатисского сельсовета.############Посёлок расположен в 12,5 км к югу от села Дивеева и 1 км к западу от города Сарова, на правом берегу реки Вичкинза (правый приток реки Сатис). Окружён смешанными лесами. Соединён асфальтовой дорогой с посёлком Цыгановка (1,5 км) и грунтовыми просёлочными дорогами с посёлком Сатис (3,5 км). Название Новостройка является сугубо официальным, местное население использует исключительно альтернативное название — Хитрый. Употребляется языковой оборот «…на Хитром». Ранее используемые названия — Песчаный, Известковый.############Основан в 1920-х годах переселенцами из соседних сёл Аламасово и Нарышкино (расположенных соответственно в 8 и 14 км к западу в Вознесенском районе).############Традиционно в посёлке жили рабочие совхоза «Вперёд» (центр в посёлке Сатис). Возле посёлка расположен карьер где активно добывали доломитовую муку и бутовый камень (в настоящее время официально закрыт).############По данным 1978 года посёлок Новостройка характеризовался как неперспективный, здесь насчитывалось 24 хозяйства и 43 жителя. Водоснабжение осуществлялось из колодцев и родников, учреждения соцкультбыта отсутствовали. В 1992 году в посёлке насчитывалось 7 хозяйств и 16 жителей, из которых 7 трудоспособного возраста. На 1 января 1995 года в посёлке имелось 6 хозяйств и 12 жителей.############В настоящее время посёлок не только остаётся жилым, но и получил развитие благодаря своей близости к святым источникам. В полукилометре расположен Казанский родник, а в 1,2 км — источник святого Серафима Саровского.############В посёлке расположен скит Дивеевского монастыря.######В 2012 году был освящён домовой храм в честь Серафима Саровского.##############################'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}],"source":["wiki[0]"]},{"cell_type":"code","execution_count":23,"id":"3d2fac88-447a-4392-9614-b532a6a7016e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3d2fac88-447a-4392-9614-b532a6a7016e","executionInfo":{"status":"ok","timestamp":1748881991556,"user_tz":-180,"elapsed":54,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}},"outputId":"0291cce9-a06b-427b-dce6-3b5b27fa6fdb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["20003"]},"metadata":{},"execution_count":23}],"source":["len(wiki)"]},{"cell_type":"markdown","id":"d088a22e-fa9e-4647-926b-15aead479c97","metadata":{"id":"d088a22e-fa9e-4647-926b-15aead479c97"},"source":["Базовая токенизация остается точно такой же"]},{"cell_type":"code","execution_count":24,"id":"0ff1c5d7-08b0-4cc2-90f5-cfe01709f04f","metadata":{"id":"0ff1c5d7-08b0-4cc2-90f5-cfe01709f04f","executionInfo":{"status":"ok","timestamp":1748881991559,"user_tz":-180,"elapsed":9,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["import re\n","from collections import Counter\n","def tokenize(text):\n","    tokens = re.sub('#+', ' ', text.lower()).split()\n","    tokens = [token.strip(punctuation) for token in tokens]\n","    tokens = [token for token in tokens if token]\n","    return tokens\n"]},{"cell_type":"markdown","id":"b34852d5-d923-4d7b-8a51-73e3bda4d59a","metadata":{"id":"b34852d5-d923-4d7b-8a51-73e3bda4d59a"},"source":["Второй базовый элемент - это нграммер, чтобы разбивать токен на символьные нграммы\n","Обратите внимание что к токену добавляются <> чтобы учесть в нграммах, что они стоят в начале или в конце"]},{"cell_type":"code","execution_count":25,"id":"040c32c0-c661-4351-bf18-996db0c6dbd5","metadata":{"id":"040c32c0-c661-4351-bf18-996db0c6dbd5","executionInfo":{"status":"ok","timestamp":1748881991563,"user_tz":-180,"elapsed":5,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["def ngrammer(raw_string, n=2):\n","    ngrams = []\n","    raw_string = ''.join(['<', raw_string, '>'])\n","    for i in range(0,len(raw_string)-n+1):\n","        ngram = ''.join(raw_string[i:i+n])\n","        if ngram == '<' or ngram == '>': # сами по себе <> как токены не нужны\n","            continue\n","        ngrams.append(ngram)\n","    return ngrams"]},{"cell_type":"markdown","id":"4b514cd9-1860-4988-b3d0-554aad49164f","metadata":{"id":"4b514cd9-1860-4988-b3d0-554aad49164f"},"source":["Следующая функция проходится по токенам и разбивает каждый токен на подсимвольные нграммы в заданном интервале"]},{"cell_type":"code","execution_count":26,"id":"540eb690-03a5-4153-b6c3-3fbd0a1d374b","metadata":{"id":"540eb690-03a5-4153-b6c3-3fbd0a1d374b","executionInfo":{"status":"ok","timestamp":1748881991569,"user_tz":-180,"elapsed":3,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["def split_tokens(tokens, min_ngram_size, max_ngram_size):\n","    tokens_with_subwords = []\n","    for token in tokens:\n","        subtokens = []\n","        for i in range(min_ngram_size, max_ngram_size+1):\n","            if len(token) > i:\n","                subtokens.extend(ngrammer(token, i))\n","        tokens_with_subwords.append(subtokens)\n","    return tokens_with_subwords\n"]},{"cell_type":"code","execution_count":27,"id":"04670a7c-b998-4e9d-95df-f671496d2920","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04670a7c-b998-4e9d-95df-f671496d2920","scrolled":true,"executionInfo":{"status":"ok","timestamp":1748881991593,"user_tz":-180,"elapsed":25,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}},"outputId":"23af2593-b2a2-430b-da03-bf824bd6f24b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['<по',\n","  'под',\n","  'одс',\n","  'дси',\n","  'сим',\n","  'имв',\n","  'мво',\n","  'вол',\n","  'оль',\n","  'льн',\n","  'ьны',\n","  'ные',\n","  'ые>',\n","  '<под',\n","  'подс',\n","  'одси',\n","  'дсим',\n","  'симв',\n","  'имво',\n","  'мвол',\n","  'воль',\n","  'ольн',\n","  'льны',\n","  'ьные',\n","  'ные>'],\n"," ['<нг',\n","  'нгр',\n","  'гра',\n","  'рам',\n","  'амм',\n","  'ммы',\n","  'мы>',\n","  '<нгр',\n","  'нгра',\n","  'грам',\n","  'рамм',\n","  'аммы',\n","  'ммы>']]"]},"metadata":{},"execution_count":27}],"source":["split_tokens(['подсимвольные', 'нграммы'], 3, 4)"]},{"cell_type":"markdown","id":"270f33a1-5b42-40ec-814d-16df7917ea70","metadata":{"id":"270f33a1-5b42-40ec-814d-16df7917ea70"},"source":["Теперь нам нужно спаппить токены и подсимвольные нграммы в индексы и для этого нужно построить словарь. Это немного сложнее чем раньше потому что мы хотим иметь в словаре и полные слова и символьные нграммы, но нам нужно иметь отдельный список только полных слов, чтобы потом иметь возможность находить ближайшие слова.\n","\n","Чтобы было удобнее со всеми переменными напишем класс для токенизации"]},{"cell_type":"code","execution_count":43,"id":"4b1c4056-c3da-43bb-816f-264b92e89fd5","metadata":{"id":"4b1c4056-c3da-43bb-816f-264b92e89fd5","executionInfo":{"status":"ok","timestamp":1748882214627,"user_tz":-180,"elapsed":6,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["class SubwordTokenizer:\n","    def __init__(self, ngram_range=(1,1), min_count=5):\n","        self.min_ngram_size, self.max_ngram_size = ngram_range\n","        self.min_count = min_count\n","        self.subword_vocab = None\n","        self.fullword_vocab = None\n","        self.fullword_vocab_tuple = None\n","        self.vocab = None\n","        self.id2word = None\n","        self.word2id = None\n","\n","    def build_vocab(self, texts):\n","        # чтобы построить словарь нужно пройти по всему корпусу и собрать частоты всех уникальных слов и нграммов\n","        unfiltered_subword_vocab = Counter()\n","        unfiltered_fullword_vocab = Counter()\n","        for text in texts:\n","            tokens = tokenize(text)\n","            unfiltered_fullword_vocab.update(tokens)\n","            subwords_per_token = split_tokens(tokens, self.min_ngram_size, self.max_ngram_size)\n","            for subwords in subwords_per_token:\n","                # в одном слове могут быть одинаковые нграммы поэтому возьмем только уникальные\n","                unfiltered_subword_vocab.update(set(subwords))\n","\n","        self.fullword_vocab = set()\n","        self.subword_vocab = set()\n","\n","        # теперь отфильтруем по частоте\n","        for word, count in unfiltered_fullword_vocab.items():\n","            if count >= self.min_count:\n","                self.fullword_vocab.add(word)\n","        # для нграммов сделаем порог побольше чтобы не создавать слишком много нграммов\n","        # и учитывать только действительно частотные\n","        for word, count in unfiltered_subword_vocab.items():\n","            if count >= (self.min_count * 100):\n","                self.subword_vocab.add(word)\n","\n","        # общий словарь\n","        self.fullword_vocab_tuple = tuple(self.fullword_vocab)\n","        self.vocab = self.fullword_vocab | self.subword_vocab\n","        self.id2word = {i:word for i,word in enumerate(self.vocab)}\n","        self.word2id = {word:i for i,word in self.id2word.items()}\n","\n","    def subword_tokenize(self, text):\n","        if self.vocab is None:\n","            raise AttributeError('Vocabulary is not built!')\n","        # разбиваем на токены\n","        tokens = tokenize(text)\n","        # каждый токен разбиваем на символьные нграммы\n","        tokens_with_subwords = split_tokens(tokens, self.min_ngram_size, self.max_ngram_size)\n","        # оставляет только токены и нграммы которые есть в словаре\n","        only_vocab_tokens_with_subwords = []\n","        for full_token, sub_tokens in zip(tokens, tokens_with_subwords):\n","            filtered = []\n","            if full_token in self.vocab:\n","                # само слово и нграммы хранятся в одном списке\n","                # но слово будет всегда первым в списке\n","                filtered.append(full_token)\n","            filtered.extend([subtoken for subtoken in set(sub_tokens) if subtoken in self.vocab])\n","            only_vocab_tokens_with_subwords.append(filtered)\n","\n","        return only_vocab_tokens_with_subwords\n","\n","    def encode(self, subword_tokenized_text):\n","        # маппим токены и нграммы в их индексы в словаре\n","        encoded_text = []\n","        for token in subword_tokenized_text:\n","            if not token:\n","                continue\n","            encoded_text.append([self.word2id[token[0]]] + [self.word2id[t] for t in set(token[1:]) if t in self.word2id and t != token[0]])\n","        return encoded_text\n","\n","    def __call__(self, text):\n","        return self.encode(self.subword_tokenize(text))"]},{"cell_type":"code","execution_count":44,"id":"2964f47c-1ab8-4b3a-8af1-b845d6a4cd7a","metadata":{"id":"2964f47c-1ab8-4b3a-8af1-b845d6a4cd7a","executionInfo":{"status":"ok","timestamp":1748882218865,"user_tz":-180,"elapsed":7,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["tokenizer = SubwordTokenizer(ngram_range=(2,4), min_count=10)"]},{"cell_type":"code","execution_count":45,"id":"8e2445c1-7e68-401a-bad8-2d19d822c15b","metadata":{"id":"8e2445c1-7e68-401a-bad8-2d19d822c15b","executionInfo":{"status":"ok","timestamp":1748882334585,"user_tz":-180,"elapsed":115721,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["tokenizer.build_vocab(wiki)"]},{"cell_type":"code","execution_count":46,"id":"318cf75d-086f-41f5-88d8-9c771201e2ea","metadata":{"id":"318cf75d-086f-41f5-88d8-9c771201e2ea","outputId":"c77bf361-9d85-494d-d011-e67e0f9dc1c0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748882334917,"user_tz":-180,"elapsed":326,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['текст',\n","  'ст',\n","  'текс',\n","  'тек',\n","  'кс',\n","  'екс',\n","  'екст',\n","  'ст>',\n","  'кст',\n","  '<т',\n","  'те',\n","  '<те',\n","  '<тек',\n","  'т>',\n","  'ек'],\n"," ['для', 'дл', '<д', 'ля', 'я>'],\n"," ['тестирования',\n","  'ест',\n","  'иро',\n","  'ния>',\n","  '<те',\n","  'ван',\n","  'тиро',\n","  'вани',\n","  'я>',\n","  'ст',\n","  'ро',\n","  'ни',\n","  'ес',\n","  'ов',\n","  'сти',\n","  'иров',\n","  '<т',\n","  'тир',\n","  'ия>',\n","  'ани',\n","  'ания',\n","  'ров',\n","  'ован',\n","  'тес',\n","  'тест',\n","  'ния',\n","  'ти',\n","  'ан',\n","  'ести',\n","  'рова',\n","  'ия',\n","  'ва',\n","  'те',\n","  'ова',\n","  'ир'],\n"," ['то',\n","  'ен',\n","  'из',\n","  'ции>',\n","  'иза',\n","  'ток',\n","  'ац',\n","  'ке',\n","  'ии',\n","  'заци',\n","  'ни',\n","  '<то',\n","  'ции',\n","  'ци',\n","  '<т',\n","  'ации',\n","  'ии>',\n","  'зац',\n","  'кен',\n","  'изац',\n","  'низа',\n","  'и>',\n","  'токе',\n","  'ок',\n","  'низ',\n","  'ени',\n","  'оке',\n","  'аци',\n","  'за']]"]},"metadata":{},"execution_count":46}],"source":["tokenizer.subword_tokenize('Текст для тестирования токенизации')"]},{"cell_type":"code","execution_count":47,"id":"2f488c48-5fad-414d-9be8-d432e062bc9b","metadata":{"id":"2f488c48-5fad-414d-9be8-d432e062bc9b","outputId":"5a8437b0-6b89-47f2-b036-272d4c0fa1c3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748882334918,"user_tz":-180,"elapsed":309,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["54860"]},"metadata":{},"execution_count":47}],"source":["len(tokenizer.vocab)"]},{"cell_type":"code","execution_count":48,"id":"e6f2a37a-c4f9-4a2b-a0b3-e8ca4dd9d104","metadata":{"id":"e6f2a37a-c4f9-4a2b-a0b3-e8ca4dd9d104","outputId":"b90a771c-3b84-4ed3-a014-7de4704d61c0","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748882334919,"user_tz":-180,"elapsed":302,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[54830,\n","  18407,\n","  40159,\n","  40402,\n","  7673,\n","  38098,\n","  46366,\n","  40722,\n","  12207,\n","  16112,\n","  5399,\n","  5799,\n","  45672,\n","  6831,\n","  21474],\n"," [53077, 12812, 53887, 42297, 49423],\n"," [33205,\n","  52505,\n","  33405,\n","  6064,\n","  5799,\n","  33718,\n","  1615,\n","  36311,\n","  49423,\n","  18407,\n","  19462,\n","  570,\n","  21980,\n","  41330,\n","  48366,\n","  29186,\n","  35259,\n","  16112,\n","  54685,\n","  29074,\n","  11696,\n","  23476,\n","  33013,\n","  40141,\n","  13849,\n","  6850,\n","  45554,\n","  40492,\n","  27286,\n","  35385,\n","  2702,\n","  20387,\n","  5399,\n","  7751,\n","  35136],\n"," [21281,\n","  27979,\n","  16097,\n","  51344,\n","  674,\n","  45901,\n","  23346,\n","  78,\n","  54200,\n","  47657,\n","  21980,\n","  51142,\n","  31303,\n","  28711,\n","  16112,\n","  28364,\n","  39708,\n","  37379,\n","  21672,\n","  31321,\n","  28817,\n","  48270,\n","  53519,\n","  10090,\n","  38152,\n","  18769,\n","  481,\n","  29700,\n","  22664]]"]},"metadata":{},"execution_count":48}],"source":["tokenizer('Текст для тестирования токенизации')"]},{"cell_type":"markdown","id":"a3bb6393-2351-436a-8aaa-58ec1c7353c0","metadata":{"id":"a3bb6393-2351-436a-8aaa-58ec1c7353c0"},"source":["Реализуем функцию которая будет генерировать батчи для обучения. Сделаем только скипграмм алгоритм. То есть нам нужны пары токен_1 - токен_2 встретившиеся в одном контексте, только для токена_1 мы еще будет учитывать его символьный нграммы, а токен_2 будет предсказывать только целиком без разбиение на поднграммы"]},{"cell_type":"code","execution_count":56,"id":"f2308cbf-cca8-4044-8c6d-80d4815f914e","metadata":{"id":"f2308cbf-cca8-4044-8c6d-80d4815f914e","executionInfo":{"status":"ok","timestamp":1748882623381,"user_tz":-180,"elapsed":94,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["def gen_batches_ft(sentences, tokenizer, window = 5, batch_size=1000, maxlen=20):\n","\n","    left_context_length = (window/2).__ceil__()\n","    right_context_length = window // 2\n","\n","    while True:\n","        X_target = []\n","        X_context = []\n","        y = []\n","\n","        for sent in sentences:\n","            sent = tokenizer(sent)\n","            for i in range(len(sent)-1):\n","                word_with_subtokens = sent[i]\n","                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n","                for context_word_with_subtokens in context:\n","                    # целевой токен всегда только целый\n","                    # мы берем первый токен из списка который вернул токенайзер\n","                    # там у нас будет лежать целое слово\n","                    only_full_word_context_token = context_word_with_subtokens[0]\n","\n","                    X_target.append(word_with_subtokens)\n","                    X_context.append(only_full_word_context_token)\n","                    y.append(1)\n","\n","                    X_target.append(word_with_subtokens)\n","                    X_context.append(tokenizer.word2id[random.choice(tokenizer.fullword_vocab_tuple)])\n","                    y.append(0)\n","\n","                    if len(X_target) >= batch_size:\n","                        # тут нам понадобится паддинг так как количество сивольных нграммов будет зависеть от длины токенов\n","                        X_target = np.array(keras.preprocessing.sequence.pad_sequences(X_target, maxlen=maxlen))\n","                        X_context = np.array(X_context)\n","                        y = np.array(y)\n","                        yield ((X_target, X_context), y)\n","                        X_target = []\n","                        X_context = []\n","                        y = []"]},{"cell_type":"code","execution_count":57,"id":"4fa2a8c6-f144-484e-b641-b89749bb710c","metadata":{"id":"4fa2a8c6-f144-484e-b641-b89749bb710c","executionInfo":{"status":"ok","timestamp":1748882623998,"user_tz":-180,"elapsed":18,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["gen = gen_batches_ft(wiki, tokenizer, batch_size=5)"]},{"cell_type":"code","execution_count":51,"id":"11d3ef2c-3bb4-4e19-9fe3-8f8592d02381","metadata":{"id":"11d3ef2c-3bb4-4e19-9fe3-8f8592d02381","outputId":"ee7674ab-b05e-4985-e804-bffbd1285105","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748882335203,"user_tz":-180,"elapsed":6,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((array([[ 1417, 26427, 15437, 13847, 30423, 36048,  6955,  5500, 51052,\n","          44023, 34395, 48829,  8363, 23121, 15798, 29917, 51070, 38998,\n","          47459, 32609],\n","         [ 1417, 26427, 15437, 13847, 30423, 36048,  6955,  5500, 51052,\n","          44023, 34395, 48829,  8363, 23121, 15798, 29917, 51070, 38998,\n","          47459, 32609],\n","         [21980, 40530, 52574, 18549,  5267, 54312, 30423, 19918, 35894,\n","          38145, 48874, 54112, 31168,  2449, 12247,  6343, 24462, 15013,\n","          36410,  4686],\n","         [21980, 40530, 52574, 18549,  5267, 54312, 30423, 19918, 35894,\n","          38145, 48874, 54112, 31168,  2449, 12247,  6343, 24462, 15013,\n","          36410,  4686],\n","         [21980, 40530, 52574, 18549,  5267, 54312, 30423, 19918, 35894,\n","          38145, 48874, 54112, 31168,  2449, 12247,  6343, 24462, 15013,\n","          36410,  4686],\n","         [21980, 40530, 52574, 18549,  5267, 54312, 30423, 19918, 35894,\n","          38145, 48874, 54112, 31168,  2449, 12247,  6343, 24462, 15013,\n","          36410,  4686]], dtype=int32),\n","  array([28042, 40462, 17650, 26298, 23405,  6131])),\n"," array([1, 0, 1, 0, 1, 0]))"]},"metadata":{},"execution_count":51}],"source":["next(gen)"]},{"cell_type":"markdown","id":"a16b8442-7830-4e92-bf2a-007eaed7354a","metadata":{"id":"a16b8442-7830-4e92-bf2a-007eaed7354a"},"source":["Код для обучения очень простой. Мы просто сопостовляет каждому токену и нграмму эмбединг и усредняем все эмбединги внутри слова, чтобы получить итоговый. По нему мы пытаемся предсказать целевое слово."]},{"cell_type":"code","execution_count":58,"id":"e2229acf-0d74-46f9-87f5-2c7f56d79fb4","metadata":{"id":"e2229acf-0d74-46f9-87f5-2c7f56d79fb4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748882664177,"user_tz":-180,"elapsed":766,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}},"outputId":"053c90c3-d2c0-4ba2-d117-f932b2624c12"},"outputs":[{"output_type":"stream","name":"stdout","text":["<KerasTensor shape=(None, 300), dtype=float32, sparse=False, name=keras_tensor_8>\n","<KerasTensor shape=(None, 300), dtype=float32, sparse=False, name=keras_tensor_9>\n"]}],"source":["inputs_target = keras.layers.Input(shape=(20,))\n","inputs_context = keras.layers.Input(shape=(1,))\n","\n","embeddings_target = keras.layers.Embedding(input_dim=len(tokenizer.vocab), output_dim=300)(inputs_target, )\n","embeddings_context = keras.layers.Embedding(input_dim=len(tokenizer.vocab), output_dim=300)(inputs_context, )\n","\n","target = keras.layers.Lambda(\n","    lambda x: tf.reduce_sum(x, axis=1), output_shape=(300,))(embeddings_target)\n","print(target)\n","context = keras.layers.Flatten()(embeddings_context)\n","print(context)\n","\n","dot = keras.layers.Dot(1)([target, context])\n","outputs = keras.layers.Activation(activation='sigmoid')(dot)\n","\n","model = keras.Model(inputs=[inputs_target, inputs_context],\n","                       outputs=outputs)\n","optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n","model.compile(optimizer=optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":59,"id":"78620544-d4e7-4d26-8351-bb99b910ec13","metadata":{"id":"78620544-d4e7-4d26-8351-bb99b910ec13","executionInfo":{"status":"ok","timestamp":1748882665850,"user_tz":-180,"elapsed":4,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["model.build([(None, 20), (None, 1)])"]},{"cell_type":"code","execution_count":60,"id":"71ab62bb-a552-41eb-9df2-bb7d4e7b5c22","metadata":{"id":"71ab62bb-a552-41eb-9df2-bb7d4e7b5c22","outputId":"ea869596-19ca-4a34-e30e-ad461c32a237","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"status":"ok","timestamp":1748882667012,"user_tz":-180,"elapsed":202,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │ \u001b[38;5;34m16,458,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │ \u001b[38;5;34m16,458,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│                     │                   │            │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,458,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,458,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│                     │                   │            │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,916,000\u001b[0m (125.56 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,916,000</span> (125.56 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,916,000\u001b[0m (125.56 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,916,000</span> (125.56 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["model.summary()"]},{"cell_type":"code","execution_count":62,"id":"d4a88c49-025a-4f9b-99c1-632dd679c061","metadata":{"id":"d4a88c49-025a-4f9b-99c1-632dd679c061","outputId":"7059de20-6a40-4c31-d60d-99372854d6da","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1748883230671,"user_tz":-180,"elapsed":4167,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m    7/10000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:31\u001b[0m 405ms/step - accuracy: 0.5885 - loss: 0.6627"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-8adb15e88388>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(gen_batches_ft(wiki[:19000],tokenizer, window=10, batch_size=100),\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_batches_ft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m19000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.fit(gen_batches_ft(wiki[:19000],tokenizer, window=10, batch_size=100),\n","          validation_data=gen_batches_ft(wiki[19000:], tokenizer, window=10, batch_size=100),\n","          batch_size=2000,\n","          steps_per_epoch=10000,\n","          validation_steps=100,\n","          epochs=5)"]},{"cell_type":"code","execution_count":null,"id":"680c2887-b0b7-4432-98cf-b8a1d2ac89ad","metadata":{"id":"680c2887-b0b7-4432-98cf-b8a1d2ac89ad","executionInfo":{"status":"aborted","timestamp":1748882335612,"user_tz":-180,"elapsed":116900,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["print(model.history.history.keys())\n","# summarize history for accuracy\n","plt.plot(model.history.history['loss'])\n","plt.plot(model.history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","id":"2859f8f3-36b8-41b4-9e85-5960ca067673","metadata":{"id":"2859f8f3-36b8-41b4-9e85-5960ca067673"},"source":["Искать похожие немного сложнее так как нам нужно для всех полных слов еще и учесть информацию об их поднграммах."]},{"cell_type":"code","execution_count":null,"id":"8f87407d-1abd-4a8c-90df-92abaa9d7bf6","metadata":{"id":"8f87407d-1abd-4a8c-90df-92abaa9d7bf6","executionInfo":{"status":"aborted","timestamp":1748882335614,"user_tz":-180,"elapsed":116900,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["embeddings = model.layers[0].get_weights()[0] # матрица со всеми эмбедингами"]},{"cell_type":"code","execution_count":null,"id":"f8606be6-2782-4a5c-882f-a7d05241898e","metadata":{"id":"f8606be6-2782-4a5c-882f-a7d05241898e","executionInfo":{"status":"aborted","timestamp":1748882335616,"user_tz":-180,"elapsed":116898,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["full_word_embeddings = np.zeros((len(tokenizer.fullword_vocab), 100)) # матрица с эмбедингами полных слов + нграммы\n","id2word = list(tokenizer.fullword_vocab)\n","\n","for i, word in enumerate(tokenizer.fullword_vocab):\n","    subwords = tokenizer(word)[0]\n","    full_word_embeddings[i] = embeddings[[i for i in subwords]].mean(axis=0)"]},{"cell_type":"code","execution_count":null,"id":"6b53ba6e-ee0d-4e05-ba2d-e1bb35b27f50","metadata":{"id":"6b53ba6e-ee0d-4e05-ba2d-e1bb35b27f50","executionInfo":{"status":"aborted","timestamp":1748882335618,"user_tz":-180,"elapsed":116896,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["def most_similar_ft(word, embeddings, tokenizer):\n","    subwords = tokenizer(word)[0]\n","    word_embedding = embeddings[[i for i in subwords]].sum(axis=0)\n","    # idxs = [tokenizer.word2id[i] for i in tokenizer.fullword_vocab]\n","    similar = [id2word[i] for i in\n","               cosine_distances(word_embedding.reshape(1, -1), full_word_embeddings).argsort()[0][:20]]\n","    return similar"]},{"cell_type":"markdown","id":"3d7d9755-1249-49de-806a-a42c0f4e596f","metadata":{"id":"3d7d9755-1249-49de-806a-a42c0f4e596f"},"source":["Из результатов поиска видно что fastext учитывает поднграмы и находит как ближайшие не только близкие по смыслу но и по форме"]},{"cell_type":"code","execution_count":null,"id":"a44f1c1c-9125-4335-a562-3ff768b39fd3","metadata":{"id":"a44f1c1c-9125-4335-a562-3ff768b39fd3","executionInfo":{"status":"aborted","timestamp":1748882335620,"user_tz":-180,"elapsed":116894,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["most_similar_ft('семья', embeddings, tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"f86b30a3-bda4-4644-af30-3550958a6ce2","metadata":{"id":"f86b30a3-bda4-4644-af30-3550958a6ce2","executionInfo":{"status":"aborted","timestamp":1748882335622,"user_tz":-180,"elapsed":116893,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["most_similar_ft(\"церковь\", embeddings, tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"c65ad6de-6869-4e3d-a5bb-689476f092dd","metadata":{"id":"c65ad6de-6869-4e3d-a5bb-689476f092dd","executionInfo":{"status":"aborted","timestamp":1748882335624,"user_tz":-180,"elapsed":116891,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":["most_similar_ft(\"делать\", embeddings, tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"88df1a15-7db3-4d4e-a772-0c804db93d3b","metadata":{"id":"88df1a15-7db3-4d4e-a772-0c804db93d3b","executionInfo":{"status":"aborted","timestamp":1748882335710,"user_tz":-180,"elapsed":116971,"user":{"displayName":"Anton Perfilev","userId":"11830477223292675146"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}